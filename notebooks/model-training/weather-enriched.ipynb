{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vad.architectures import STAD\n",
    "from vad.datasets import TrajectoryDataset, ExactBatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T07:18:29.972058Z",
     "start_time": "2025-04-17T07:18:29.967461Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCIVs9481Ais",
    "outputId": "b726bc73-9411-4201-8d74-dc59ac14551b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(8)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseweather_epochs_150_pat_150_embed_32_wd_0.1_lr_3e-05_hgmm_32_lae_32_comp_30\n"
     ]
    }
   ],
   "source": [
    "exp_type = 'baseweather'\n",
    "include_weather = True\n",
    "n_weather_vars = 5\n",
    "embed_dim = 32\n",
    "weight_decay = 0.1\n",
    "dropout = 0.1\n",
    "epochs = 250\n",
    "learning_rate = 1e-5\n",
    "hidden_dim_gmm = 32\n",
    "latent_dim_ae = 32\n",
    "patience = epochs\n",
    "n_head_te = 8\n",
    "n_layers_te = 4\n",
    "n_components = 30\n",
    "eps_gmm = 1e-7\n",
    "eps_loss = 1\n",
    "\n",
    "experiment_name = f'{exp_type}_epochs_{epochs}_pat_{patience}_embed_{embed_dim}_wd_{weight_decay}_lr_{learning_rate}_hgmm_{hidden_dim_gmm}_lae_{latent_dim_ae}_comp_{n_components}'\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAD Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lZP9BoGDn-F",
    "outputId": "86af3f2f-2fbb-445e-eb43-a02ccb6d0bf3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAD(\n",
      "  (embedding): TrajectoryEmbedding(\n",
      "    (lat_embed): Embedding(400, 32)\n",
      "    (lon_embed): Embedding(400, 32)\n",
      "    (sog_embed): Embedding(30, 32)\n",
      "    (cog_embed): Embedding(72, 32)\n",
      "  )\n",
      "  (transenc): TrajectoryTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-3): 4 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (lat_out): Linear(in_features=128, out_features=400, bias=True)\n",
      "  (lon_out): Linear(in_features=128, out_features=400, bias=True)\n",
      "  (sog_out): Linear(in_features=128, out_features=30, bias=True)\n",
      "  (cog_out): Linear(in_features=128, out_features=72, bias=True)\n",
      "  (ae): Autoencoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=320, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=320, out_features=80, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=80, out_features=32, bias=True)\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=80, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=80, out_features=320, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=320, out_features=1280, bias=True)\n",
      "      (7): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (gmm): GMMEstimationNetwork(\n",
      "    (mlp): Sequential(\n",
      "      (0): LayerNorm((44,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): Linear(in_features=44, out_features=32, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=16, out_features=30, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "stad = STAD(n_lat_bins=400,\n",
    "            n_lon_bins=400,\n",
    "            n_sog_bins=30,\n",
    "            n_cog_bins=72,\n",
    "            max_seq_len=10,\n",
    "            embed_dim=embed_dim,\n",
    "            dropout=dropout,\n",
    "            nhead_te=n_head_te,\n",
    "            n_layers_te=n_layers_te,\n",
    "            latent_dim_ae=latent_dim_ae,\n",
    "            n_weather_vars=n_weather_vars,\n",
    "            hidden_dim_gmm=hidden_dim_gmm,\n",
    "            eps_gmm=eps_gmm,\n",
    "            n_components_gmm=n_components).to(device)\n",
    "print(stad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCHleP5KDn-F"
   },
   "source": [
    "# STAD Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gmm_penalty(sigma, epsilon=eps_loss):\n",
    "    \"\"\"\n",
    "    Vectorized computation of GMM penalty (sum of reciprocals of diagonal elements)\n",
    "\n",
    "    sigma: Component covariances. Shape: [num_components, input_dim, input_dim]\n",
    "    epsilon: Small value for numerical stability\n",
    "    \"\"\"\n",
    "    # Extract diagonal elements from all covariance matrices at once\n",
    "    # Shape: [num_components, input_dim]\n",
    "    diag_elements = torch.diagonal(sigma, dim1=-2, dim2=-1)\n",
    "\n",
    "    # Add epsilon for numerical stability before taking reciprocal\n",
    "    # This prevents division by very small numbers\n",
    "    penalty = torch.sum(1.0 / (diag_elements + epsilon))\n",
    "\n",
    "    return penalty\n",
    "\n",
    "def compute_full_loss(penalty, transformer_loss, energy, d,\n",
    "                      lambda_1=1, lambda_2=1, lambda_3=5e-3):\n",
    "                      # λ₁=1, λ₂=1, λ₃=0.005 as in the STAD publication\n",
    "    return transformer_loss + (lambda_1 * energy) + (lambda_2 * d) + (lambda_3 * penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAD Unbiased Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_training_set(model, train_dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the training set with model in eval mode to get unbiased loss.\n",
    "    Returns the average training loss without gradients or dropout effects.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(train_dataloader, desc=\"Evaluating Training Set\"):\n",
    "            # Move data to device\n",
    "            inputs = {k: v.to(device) for k, v in batch.get('src_window').items()}\n",
    "            targets = {k: v.to(device) for k, v in batch.get('tgt_window').items()}\n",
    "            weather_stats = batch.get('weather_stats', None).to(device)\n",
    "\n",
    "            # Forward pass (will use testing=False path due to eval mode)\n",
    "            l, energy, d_h, sigma = model(inputs, targets, weather_stats)\n",
    "            l, energy, d_h = l.mean(), energy.mean(), d_h.mean()\n",
    "\n",
    "            # Calculate loss components\n",
    "            penalty = calculate_gmm_penalty(sigma)\n",
    "            penalty = penalty.mean()\n",
    "\n",
    "            # Compute final loss\n",
    "            train_eval_loss = compute_full_loss(penalty, l, energy, d_h).mean()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_train_loss += train_eval_loss.item()\n",
    "\n",
    "    # Return average loss\n",
    "    return total_train_loss / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAD Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, device):\n",
    "\n",
    "    total_val_loss = 0\n",
    "    total_energy = 0\n",
    "    total_te_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batchidx, batch in enumerate(tqdm(dataloader, desc=\"Validation\")):\n",
    "\n",
    "        # Move data to device\n",
    "        inputs = {k: v.to(device) for k, v in batch.get('src_window').items()}\n",
    "        targets = {k: v.to(device) for k, v in batch.get('tgt_window').items()}\n",
    "        weather_stats = batch.get('weather_stats', None).to(device)\n",
    "\n",
    "        # Pass data to model\n",
    "        l, energy, d_h, sigma = model(inputs, targets, weather_stats)\n",
    "        l, energy, d_h = l.mean(), energy.mean(), d_h.mean()\n",
    "\n",
    "        # Calculate loss components\n",
    "        penalty = calculate_gmm_penalty(sigma)\n",
    "        penalty = penalty.mean()\n",
    "\n",
    "        # Compute the final loss\n",
    "        stad_loss = compute_full_loss(penalty, l, energy, d_h)\n",
    "        stad_loss = stad_loss.mean()\n",
    "\n",
    "        # Update total validation loss and total energy\n",
    "        total_val_loss += stad_loss.item()\n",
    "        total_energy += energy.item()\n",
    "        total_te_loss += l.item()\n",
    "\n",
    "    # Calculate average validation loss and energy\n",
    "    avg_val_loss = total_val_loss / len(dataloader)\n",
    "    avg_energy = total_energy / len(dataloader)\n",
    "    avg_te_loss = total_te_loss / len(dataloader)\n",
    "    return avg_val_loss, avg_energy, avg_te_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTx9iY5XDn-F"
   },
   "source": [
    "# STAD Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_dataloader,\n",
    "          valid_dataloader,\n",
    "          optimizer,\n",
    "          scheduler,\n",
    "          num_epochs,\n",
    "          device,\n",
    "          patience,\n",
    "          save_dir='./models'):\n",
    "\n",
    "    # Create directory\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize TensorBoard writer\n",
    "    timestamp = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "    writer = SummaryWriter(log_dir=f'./runs/{timestamp}_{experiment_name}')\n",
    "\n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        # Training phase\n",
    "        for batchidx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")):\n",
    "\n",
    "            # Move data to device\n",
    "            inputs = {k: v.to(device) for k, v in batch.get('src_window').items()}\n",
    "            targets = {k: v.to(device) for k, v in batch.get('tgt_window').items()}\n",
    "            weather_stats = batch.get('weather_stats', None).to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Pass data to model\n",
    "            l, energy, d_h, sigma = model(inputs, targets, weather_stats)\n",
    "            l, energy, d_h = l.mean(), energy.mean(), d_h.mean()\n",
    "\n",
    "            # Calculate loss components\n",
    "            penalty = calculate_gmm_penalty(sigma)\n",
    "            penalty = penalty.mean()\n",
    "\n",
    "            # Compute the final loss\n",
    "            stad_loss = compute_full_loss(penalty, l, energy, d_h).mean()\n",
    "\n",
    "            # Update total loss for epoch\n",
    "            train_loss += stad_loss.mean()\n",
    "\n",
    "            # Print progress\n",
    "            if batchidx % 200 == 0:\n",
    "                writer.add_scalar('Batch/te_loss', l, epoch * len(train_dataloader) + batchidx)\n",
    "                writer.add_scalar('Batch/Energy', energy, epoch * len(train_dataloader) + batchidx)\n",
    "                writer.add_scalar('Batch/train_loss', stad_loss, epoch * len(train_dataloader) + batchidx)\n",
    "                writer.add_scalar('Batch/Penalty', penalty*0.005, epoch * len(train_dataloader) + batchidx)\n",
    "                print(f'Batch {batchidx}/{len(train_dataloader)} | Loss: {stad_loss:.6f}')\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            stad_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss = train_loss.detach()\n",
    "\n",
    "        # Calculate average training loss for this epoch\n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        true_loss = evaluate_training_set(model, train_dataloader, device) # already averaged\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, avg_energy, avg_te_loss = validate(model, valid_dataloader, device)\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar('Epoch/train_loss', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Epoch/validation_loss', val_loss, epoch)\n",
    "        writer.add_scalar('Epoch/avg_energy', avg_energy, epoch)\n",
    "        writer.add_scalar('Epoch/avg_te_loss', avg_te_loss, epoch)\n",
    "        writer.add_scalar('Epoch/learning_rate', scheduler.get_last_lr()[0], epoch)\n",
    "        writer.add_scalar('Epoch/true_loss', true_loss, epoch)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Average Train Loss: {avg_train_loss:.6f} | Average Validation Loss: {val_loss:.6f}')\n",
    "\n",
    "        # Save latest model\n",
    "        latest_model_path = os.path.join(save_dir, 'STAD_latest.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': val_loss\n",
    "        }, latest_model_path)\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "\n",
    "            # Save best model\n",
    "            best_model_path = os.path.join(save_dir, 'STAD_best.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': val_loss\n",
    "            }, best_model_path)\n",
    "            print(f\"Saved new best model with validation loss: {val_loss:.6f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Validation loss did not improve. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "            break\n",
    "\n",
    "        # Free cached memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    writer.close()\n",
    "\n",
    "    # Load the best model\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with validation loss: {checkpoint['val_loss']:.6f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_dataset_train = TrajectoryDataset(ds_type='train',\n",
    "                                       lat_bins=400,\n",
    "                                       lon_bins=400,\n",
    "                                       sog_bins=30,\n",
    "                                       cog_bins=72,\n",
    "                                       file_directory='../../data',\n",
    "                                       filename='joined-train-stad-weather.pkl',\n",
    "                                       include_weather=include_weather)\n",
    "\n",
    "traj_dataset_valid = TrajectoryDataset(ds_type='valid',\n",
    "                                       lat_bins=400,\n",
    "                                       lon_bins=400,\n",
    "                                       sog_bins=30,\n",
    "                                       cog_bins=72,\n",
    "                                       file_directory='../../data',\n",
    "                                       filename='joined-valid-stad-weather.pkl',\n",
    "                                       include_weather=include_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_sampler = ExactBatchSampler(traj_dataset_train.batch_boundaries, shuffle_batches=True)\n",
    "valid_batch_sampler = ExactBatchSampler(traj_dataset_valid.batch_boundaries, shuffle_batches=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = data.DataLoader(traj_dataset_train, batch_sampler=train_batch_sampler, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "data_loader_valid = data.DataLoader(traj_dataset_valid, batch_sampler=valid_batch_sampler, num_workers=4, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(stad.parameters(),\n",
    "#                 betas=(0.5, 0.999), # Lower b1 because of variation in batch (trajectory) length\n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "scheduler = OneCycleLR(optimizer,\n",
    "                    max_lr=learning_rate,            # Peak learning rate\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=len(data_loader_train),\n",
    "                    anneal_strategy='cos'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "vZbrqdYuGffP",
    "outputId": "51bd7f54-5298-408b-a354-4635df8d587c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:   0%|          | 5/4538 [00:00<06:28, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/4538 | Loss: 262.495758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:   5%|▍         | 205/4538 [00:05<01:53, 38.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/4538 | Loss: 255.066711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:   9%|▉         | 405/4538 [00:11<01:48, 38.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400/4538 | Loss: 249.060272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  13%|█▎        | 605/4538 [00:16<01:43, 38.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600/4538 | Loss: 249.066589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  18%|█▊        | 805/4538 [00:21<01:37, 38.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800/4538 | Loss: 252.475296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  22%|██▏       | 1005/4538 [00:26<01:32, 38.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/4538 | Loss: 259.411865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  27%|██▋       | 1205/4538 [00:31<01:27, 38.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200/4538 | Loss: 243.867645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  31%|███       | 1405/4538 [00:37<01:21, 38.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400/4538 | Loss: 244.791168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  35%|███▌      | 1605/4538 [00:42<01:15, 39.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600/4538 | Loss: 251.855713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  40%|███▉      | 1805/4538 [00:47<01:09, 39.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800/4538 | Loss: 248.831116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  44%|████▍     | 2005/4538 [00:52<01:05, 38.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/4538 | Loss: 247.924301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  49%|████▊     | 2205/4538 [00:57<01:00, 38.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200/4538 | Loss: 248.797348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  53%|█████▎    | 2405/4538 [01:02<00:54, 39.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400/4538 | Loss: 235.794586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  57%|█████▋    | 2605/4538 [01:08<00:49, 38.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600/4538 | Loss: 246.027588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  62%|██████▏   | 2804/4538 [01:12<00:42, 41.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800/4538 | Loss: 239.652573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  66%|██████▌   | 3004/4538 [01:17<00:37, 41.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/4538 | Loss: 247.641144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  71%|███████   | 3204/4538 [01:22<00:32, 41.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3200/4538 | Loss: 238.311249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  75%|███████▌  | 3404/4538 [01:27<00:28, 39.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3400/4538 | Loss: 238.166336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  79%|███████▉  | 3604/4538 [01:32<00:22, 41.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3600/4538 | Loss: 229.683350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  84%|████████▍ | 3804/4538 [01:37<00:17, 41.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3800/4538 | Loss: 245.392303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  88%|████████▊ | 4004/4538 [01:42<00:12, 41.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/4538 | Loss: 242.506012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  93%|█████████▎| 4204/4538 [01:46<00:08, 41.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4200/4538 | Loss: 239.732239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]:  97%|█████████▋| 4404/4538 [01:51<00:03, 41.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4400/4538 | Loss: 244.842697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 [Train]: 100%|██████████| 4538/4538 [01:55<00:00, 39.46it/s]\n",
      "Evaluating Training Set: 100%|██████████| 4538/4538 [00:34<00:00, 129.89it/s]\n",
      "Validation: 100%|██████████| 787/787 [00:07<00:00, 99.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 | Average Train Loss: 245.467941 | Average Validation Loss: 238.208952\n",
      "Saved new best model with validation loss: 238.208952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:   0%|          | 4/4538 [00:00<02:18, 32.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/4538 | Loss: 247.537109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:   4%|▍         | 204/4538 [00:04<01:45, 40.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/4538 | Loss: 241.086487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:   9%|▉         | 404/4538 [00:09<01:40, 41.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400/4538 | Loss: 244.331940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  13%|█▎        | 604/4538 [00:14<01:35, 41.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600/4538 | Loss: 240.171906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  18%|█▊        | 804/4538 [00:19<01:33, 39.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800/4538 | Loss: 223.790283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  22%|██▏       | 1004/4538 [00:24<01:26, 40.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/4538 | Loss: 236.038574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  27%|██▋       | 1204/4538 [00:29<01:21, 41.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200/4538 | Loss: 241.797272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  31%|███       | 1404/4538 [00:34<01:15, 41.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400/4538 | Loss: 252.090958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  35%|███▌      | 1604/4538 [00:39<01:11, 40.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600/4538 | Loss: 247.216934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  40%|███▉      | 1804/4538 [00:43<01:06, 41.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800/4538 | Loss: 223.977783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  44%|████▍     | 2004/4538 [00:48<01:01, 41.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/4538 | Loss: 240.647217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  48%|████▊     | 2199/4538 [00:53<00:56, 41.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200/4538 | Loss: 228.856964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  53%|█████▎    | 2404/4538 [00:58<00:52, 40.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400/4538 | Loss: 225.495117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  57%|█████▋    | 2604/4538 [01:03<00:47, 40.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600/4538 | Loss: 236.173203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  62%|██████▏   | 2804/4538 [01:08<00:42, 41.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800/4538 | Loss: 228.678635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  66%|██████▌   | 3004/4538 [01:13<00:37, 41.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/4538 | Loss: 200.891861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  71%|███████   | 3208/4538 [01:18<00:34, 38.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3200/4538 | Loss: 211.581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  75%|███████▌  | 3408/4538 [01:23<00:29, 38.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3400/4538 | Loss: 224.133652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  80%|███████▉  | 3608/4538 [01:28<00:24, 38.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3600/4538 | Loss: 238.113724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  84%|████████▍ | 3808/4538 [01:34<00:19, 38.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3800/4538 | Loss: 206.277634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  88%|████████▊ | 4008/4538 [01:39<00:13, 38.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/4538 | Loss: 200.961319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  93%|█████████▎| 4208/4538 [01:44<00:08, 38.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4200/4538 | Loss: 242.298019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]:  97%|█████████▋| 4408/4538 [01:49<00:03, 38.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4400/4538 | Loss: 225.157837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 [Train]: 100%|██████████| 4538/4538 [01:53<00:00, 40.11it/s]\n",
      "Evaluating Training Set: 100%|██████████| 4538/4538 [00:34<00:00, 131.80it/s]\n",
      "Validation: 100%|██████████| 787/787 [00:08<00:00, 95.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 | Average Train Loss: 233.738708 | Average Validation Loss: 229.052732\n",
      "Saved new best model with validation loss: 229.052732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 [Train]:   0%|          | 0/4538 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/4538 | Loss: 243.278458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Training Set: 100%|██████████| 4538/4538 [00:35<00:00, 128.49it/s]\n",
      "Validation: 100%|██████████| 787/787 [00:07<00:00, 100.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 | Average Train Loss: 225.924652 | Average Validation Loss: 222.363145\n",
      "Saved new best model with validation loss: 222.363145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:   0%|          | 8/4538 [00:00<02:02, 37.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/4538 | Loss: 224.754150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:   5%|▍         | 208/4538 [00:05<01:46, 40.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/4538 | Loss: 211.183182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:   9%|▉         | 408/4538 [00:10<01:41, 40.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400/4538 | Loss: 213.206833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  13%|█▎        | 608/4538 [00:14<01:36, 40.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600/4538 | Loss: 217.351303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  18%|█▊        | 808/4538 [00:19<01:30, 41.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800/4538 | Loss: 233.282349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  22%|██▏       | 1008/4538 [00:24<01:26, 40.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/4538 | Loss: 231.230087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  27%|██▋       | 1208/4538 [00:29<01:21, 40.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200/4538 | Loss: 210.341629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  31%|███       | 1408/4538 [00:34<01:16, 40.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400/4538 | Loss: 222.254761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  35%|███▌      | 1608/4538 [00:39<01:11, 41.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600/4538 | Loss: 181.244263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  40%|███▉      | 1808/4538 [00:44<01:06, 40.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800/4538 | Loss: 190.467758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  44%|████▍     | 2008/4538 [00:49<01:01, 40.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/4538 | Loss: 201.681763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  49%|████▊     | 2208/4538 [00:54<00:56, 40.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200/4538 | Loss: 228.024780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  53%|█████▎    | 2408/4538 [00:58<00:52, 40.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400/4538 | Loss: 208.051590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  57%|█████▋    | 2608/4538 [01:03<00:46, 41.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600/4538 | Loss: 219.684998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  62%|██████▏   | 2808/4538 [01:08<00:42, 40.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800/4538 | Loss: 243.238953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  66%|██████▋   | 3008/4538 [01:13<00:37, 40.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/4538 | Loss: 216.299866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  71%|███████   | 3208/4538 [01:18<00:32, 40.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3200/4538 | Loss: 225.681839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  75%|███████▌  | 3408/4538 [01:23<00:28, 40.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3400/4538 | Loss: 225.128998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  80%|███████▉  | 3608/4538 [01:28<00:22, 40.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3600/4538 | Loss: 218.221680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  84%|████████▍ | 3808/4538 [01:33<00:17, 40.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3800/4538 | Loss: 222.509491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  88%|████████▊ | 4008/4538 [01:38<00:13, 40.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/4538 | Loss: 220.146133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  93%|█████████▎| 4208/4538 [01:42<00:08, 40.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4200/4538 | Loss: 225.300995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]:  97%|█████████▋| 4408/4538 [01:47<00:03, 40.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4400/4538 | Loss: 177.244751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 [Train]: 100%|██████████| 4538/4538 [01:51<00:00, 40.88it/s]\n",
      "Evaluating Training Set: 100%|██████████| 4538/4538 [00:34<00:00, 130.05it/s]\n",
      "Validation: 100%|██████████| 787/787 [00:07<00:00, 99.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 | Average Train Loss: 219.758621 | Average Validation Loss: 216.655289\n",
      "Saved new best model with validation loss: 216.655289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:   0%|          | 0/4538 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/4538 | Loss: 176.053726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:   5%|▍         | 208/4538 [00:05<01:46, 40.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/4538 | Loss: 212.309402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:   9%|▉         | 408/4538 [00:09<01:40, 41.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400/4538 | Loss: 250.735947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  13%|█▎        | 608/4538 [00:14<01:35, 41.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600/4538 | Loss: 205.490814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  18%|█▊        | 808/4538 [00:19<01:31, 40.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800/4538 | Loss: 218.314987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  22%|██▏       | 1008/4538 [00:24<01:26, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/4538 | Loss: 246.020584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  27%|██▋       | 1208/4538 [00:29<01:20, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200/4538 | Loss: 225.082123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  31%|███       | 1408/4538 [00:34<01:17, 40.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400/4538 | Loss: 224.887070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  35%|███▌      | 1608/4538 [00:39<01:11, 40.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600/4538 | Loss: 218.640610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  40%|███▉      | 1808/4538 [00:44<01:06, 41.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800/4538 | Loss: 213.982162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  44%|████▍     | 2008/4538 [00:48<01:02, 40.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/4538 | Loss: 195.032974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  49%|████▊     | 2208/4538 [00:53<00:56, 41.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200/4538 | Loss: 218.859787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  53%|█████▎    | 2408/4538 [00:58<00:51, 41.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400/4538 | Loss: 227.583435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  57%|█████▋    | 2608/4538 [01:03<00:46, 41.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600/4538 | Loss: 220.849731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  62%|██████▏   | 2808/4538 [01:08<00:42, 41.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800/4538 | Loss: 195.304108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  66%|██████▋   | 3008/4538 [01:13<00:37, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/4538 | Loss: 186.671280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  71%|███████   | 3208/4538 [01:18<00:32, 41.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3200/4538 | Loss: 233.786514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  75%|███████▌  | 3408/4538 [01:23<00:27, 41.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3400/4538 | Loss: 215.724243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  80%|███████▉  | 3608/4538 [01:27<00:22, 40.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3600/4538 | Loss: 210.709641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  84%|████████▍ | 3808/4538 [01:32<00:17, 41.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3800/4538 | Loss: 198.597778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  88%|████████▊ | 4008/4538 [01:37<00:12, 41.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/4538 | Loss: 215.873718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  93%|█████████▎| 4208/4538 [01:42<00:08, 40.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4200/4538 | Loss: 203.593384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]:  97%|█████████▋| 4408/4538 [01:47<00:03, 41.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4400/4538 | Loss: 206.408813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 [Train]: 100%|██████████| 4538/4538 [01:50<00:00, 41.06it/s]\n",
      "Evaluating Training Set: 100%|█████████▉| 4537/4538 [00:34<00:00, 127.38it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 118/150 [Train]:   5%|▍         | 207/4538 [00:05<01:51, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/4538 | Loss: 88.834511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:   9%|▉         | 407/4538 [00:10<01:46, 38.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400/4538 | Loss: 86.875618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  13%|█▎        | 607/4538 [00:15<01:34, 41.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600/4538 | Loss: 75.644554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  18%|█▊        | 807/4538 [00:20<01:29, 41.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800/4538 | Loss: 80.727486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  22%|██▏       | 1007/4538 [00:25<01:25, 41.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/4538 | Loss: 74.778595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  27%|██▋       | 1207/4538 [00:29<01:20, 41.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200/4538 | Loss: 83.501846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  31%|███       | 1407/4538 [00:34<01:15, 41.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400/4538 | Loss: 76.222595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  35%|███▌      | 1607/4538 [00:39<01:10, 41.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600/4538 | Loss: 75.803482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  40%|███▉      | 1807/4538 [00:44<01:05, 41.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800/4538 | Loss: 78.951370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  44%|████▍     | 2007/4538 [00:49<01:01, 41.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/4538 | Loss: 68.682739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  49%|████▊     | 2207/4538 [00:53<00:56, 41.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200/4538 | Loss: 75.101128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  53%|█████▎    | 2407/4538 [00:58<00:51, 41.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400/4538 | Loss: 71.408676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  57%|█████▋    | 2607/4538 [01:03<00:46, 41.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600/4538 | Loss: 84.737556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  62%|██████▏   | 2807/4538 [01:08<00:41, 41.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800/4538 | Loss: 86.887650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  66%|██████▋   | 3007/4538 [01:13<00:37, 41.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/4538 | Loss: 76.128128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  71%|███████   | 3207/4538 [01:18<00:31, 41.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3200/4538 | Loss: 93.717628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  75%|███████▌  | 3405/4538 [01:23<00:29, 38.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3400/4538 | Loss: 105.352951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  79%|███████▉  | 3605/4538 [01:28<00:24, 38.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3600/4538 | Loss: 80.305649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  84%|████████▍ | 3805/4538 [01:33<00:18, 38.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3800/4538 | Loss: 74.345039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  88%|████████▊ | 4005/4538 [01:38<00:13, 38.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/4538 | Loss: 98.085579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  93%|█████████▎| 4205/4538 [01:43<00:08, 38.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4200/4538 | Loss: 87.673737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]:  97%|█████████▋| 4405/4538 [01:48<00:03, 38.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4400/4538 | Loss: 95.243599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 [Train]: 100%|██████████| 4538/4538 [01:52<00:00, 40.42it/s]\n",
      "Evaluating Training Set: 100%|██████████| 4538/4538 [00:33<00:00, 135.92it/s]\n",
      "Validation: 100%|██████████| 787/787 [00:07<00:00, 98.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 | Average Train Loss: 84.049850 | Average Validation Loss: 87.973023\n",
      "Validation loss did not improve. Patience: 2/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:   0%|          | 0/4538 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/4538 | Loss: 84.514412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:   4%|▍         | 204/4538 [00:04<01:44, 41.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/4538 | Loss: 87.315430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:   9%|▉         | 404/4538 [00:09<01:40, 41.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400/4538 | Loss: 98.388863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  13%|█▎        | 604/4538 [00:14<01:34, 41.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600/4538 | Loss: 67.909744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  18%|█▊        | 808/4538 [00:19<01:35, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800/4538 | Loss: 98.889496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  22%|██▏       | 1008/4538 [00:24<01:30, 38.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/4538 | Loss: 67.358582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  27%|██▋       | 1208/4538 [00:30<01:25, 38.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200/4538 | Loss: 80.756119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  31%|███       | 1408/4538 [00:35<01:20, 39.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400/4538 | Loss: 91.967186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  35%|███▌      | 1608/4538 [00:40<01:15, 38.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600/4538 | Loss: 90.132370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  40%|███▉      | 1808/4538 [00:45<01:09, 39.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800/4538 | Loss: 80.174362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  44%|████▍     | 2008/4538 [00:50<01:04, 38.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/4538 | Loss: 79.741928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  49%|████▊     | 2208/4538 [00:55<00:59, 38.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200/4538 | Loss: 84.326874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  53%|█████▎    | 2408/4538 [01:00<00:54, 38.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400/4538 | Loss: 74.632973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  57%|█████▋    | 2608/4538 [01:05<00:49, 38.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600/4538 | Loss: 89.718842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  62%|██████▏   | 2808/4538 [01:11<00:44, 38.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800/4538 | Loss: 87.861969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  66%|██████▋   | 3008/4538 [01:16<00:39, 38.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/4538 | Loss: 78.866211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  71%|███████   | 3208/4538 [01:21<00:34, 38.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3200/4538 | Loss: 95.901909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  75%|███████▌  | 3408/4538 [01:26<00:29, 38.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3400/4538 | Loss: 90.447136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  80%|███████▉  | 3608/4538 [01:31<00:23, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3600/4538 | Loss: 70.862015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  84%|████████▍ | 3808/4538 [01:36<00:18, 38.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3800/4538 | Loss: 68.060440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  88%|████████▊ | 4008/4538 [01:41<00:13, 38.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/4538 | Loss: 88.612831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  93%|█████████▎| 4208/4538 [01:47<00:08, 38.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4200/4538 | Loss: 98.464737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]:  97%|█████████▋| 4408/4538 [01:52<00:03, 38.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4400/4538 | Loss: 76.593567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 [Train]: 100%|██████████| 4538/4538 [01:55<00:00, 39.27it/s]\n",
      "Evaluating Training Set: 100%|██████████| 4538/4538 [00:33<00:00, 134.62it/s]\n",
      "Validation: 100%|██████████| 787/787 [00:07<00:00, 98.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 | Average Train Loss: 84.028770 | Average Validation Loss: 87.966630\n",
      "Validation loss did not improve. Patience: 3/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/150 [Train]:   0%|          | 0/4538 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/4538 | Loss: 77.911392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/150 [Train]:   4%|▍         | 204/4538 [00:04<01:44, 41.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/4538 | Loss: 71.563339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/150 [Train]:   7%|▋         | 334/4538 [00:08<01:40, 41.94it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = train(stad,\n",
    "                    data_loader_train,\n",
    "                    data_loader_valid,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    num_epochs=epochs,\n",
    "                    device=device,\n",
    "                    patience=patience,\n",
    "                    save_dir=f'./models/{experiment_name}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "vessel-anomaly-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
